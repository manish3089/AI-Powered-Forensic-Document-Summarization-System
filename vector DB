import os
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

# 1. Load embedding model
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# 2. Path to your text files
folder_path = "legal_docs/"
documents = []
file_names = []

# 3. Read all files
for file in os.listdir(folder_path):
    if file.endswith(".txt"):
        with open(os.path.join(folder_path, file), "r", encoding="utf-8") as f:
            text = f.read()
            documents.append(text)
            file_names.append(file)

# 4. Convert to embeddings
embeddings = model.encode(documents)

# 5. Create FAISS index
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))

# 6. Save index for later use
faiss.write_index(index, "legal_index.faiss")

# Save mapping of file names
with open("doc_names.txt", "w", encoding="utf-8") as f:
    for name in file_names:
        f.write(name + "\n")

print("âœ… Vector database created with", len(documents), "documents")

#
